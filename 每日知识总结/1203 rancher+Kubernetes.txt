Rancher

1. rancher是一个开源的企业级容器管理平台
提供了在生产环境中使用的管理Docker和Kubernetes的全栈式容器部署与管理平台
企业再也不必自己使用一系列的开源软件去从头搭建容器服务平台

2. Rancher由四部分组成：
	
	- 基础设施编排：

		可以使用任何公有云或者私有云的Linux主机资源。Linux主机可以是虚拟机，也可以是物理机，仅需要主机有CPU，内存，本地磁盘和网络资源

		rancher为运行容器化的应用实现了一层灵活的基础设施服务。Rancher的基础设施包括：网络、储存
		负责均衡、DNS和安全模块。

		Rancher的基础设施服务也是通过容器部署的，所以同样Rancher的基础设施服务可以运行在任何Linux主机上

	- 容器编排与调度：

		很多用户都会选择使用容器编排调度框架来运行容器化应用。Rancher包含了当前全部的主流的编排调度引擎，例如Docker Swarm，Kubernetes和Mesos。同一个用户可以创建Swarm或者K8s集群。并且可以使用原生的Swarm或者K8s工具管理应用。

		除了Swarm，Kubernets和Mesos之外，Rancher还支持自己的Cattle容器编排调度引擎。Cattle被广泛用于编排Rancher自己的基础设施服务和Swarm集群，K8s集群和Mesos集群的配置，管理和升级。

	- 应用商店：

		Rancher的用户可以在应用商店里一键部署由多个容器组成的应用。用户可以管理这个部署的应用，并且可以在这个应用有新的可用版本时进行自动化的升级。Rancher提供了一个由Rancher社区维护的应用商店，其中包括了一系列的流行应用。Rancher的用户也可以创建自己的私有应用商店。

	- 企业级权限管理：

		Rancher支持灵活的插件式的用户认证。支持Active Directory， LDAP， Github等认证方式。
		Rancher支持在环境级别的基于角色的访问控制（RBAC），可以通过角色来配置某个用户或者用户组对开发环境或者生产环境的访问权限


Kubernetes：

1. Kubernetes, also known as K8s, is an open-source system for automating deployment, scaling, and management of containerized applications.

	- Planet Scale:
		
		Designed on the same principles that allows Google to run billions of containers a week, Kubernetes can scale without increasing your ops team.

	- Never Outgrow:

		Whether testing locally or running a global enterprise, Kubernetes flexibility grows with you to deliver your applications consistenely and easily no matter how complex you need is.

	- Run K8s anywhere:

		Kubernetes is open resource giving you the freedom to take advantage of on-premises 预置, hybrid 混合, or public cloud infrastracture, letting you effortlessly move workloads to where it matters to you.


2. Features：

	- Automated rollouts and rollbacks:
		K8s progressively rolls out changes changes to your application or its configuration, while monitoring application health to ensure it doesn't kill all your instances at the same time. If something goes woring, K8s will rollback the change for you. Take advantage of a growing ecosystem of deployment solutions.

	- Service discovery and load balancing
		no need to modify your application to use an unfamiliar service discovery mechanism. K8s gives Pods their own IP addresses and a single DNS name for a set of Pods, and can load-balance across them.

	- Service Topology
		Routing of service traffic based upon cluster topology

	- Storage orchestration
		Automatically mount the storage system of your choice, whether from local storage, a public cloud provider such as GCP or AWS, or a network storage system such as NFS...

	- Secret and configuration management
		Deploy an update secretes and application configuration without rebuilding your image and without exposing secrets in your stack configuration

	- Automatic bin packing
		Automatically places containsers based on their resource requirements and other constrains, while not sacrificing availability. Mix critical and best-effort workloads in order to drive up utilization and save even more resources.

	- Batch execution 
		In addition to services, K8s can manage your batch and CI workloads, replacing continers that fail, if desired.

	- IPv4/IPv6 dual-stack
		Allocation of IPv4 and IPv6 addresses to Pods and Services.

	- Horizontal scaling
		Scale your application up and down with a simple command, with a UI, or automatically based on CPU usage.

	- Self healing
		Restarts containers that fail, replaces and reschedules containers when nodes die, kills containers that don't respond to your user-defined health check, and doesn't advertice them to clients until they are ready to serve.








